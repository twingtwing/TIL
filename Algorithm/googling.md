+1. HashTable

    (데이터 접근 구조)
    F(key) -> HashCode -> Index -> Value

장점 : 검색속도가 매우 빠름 왜냐하면, Hash함수를 통해 만든 HashCode가 정수이기때문에 배열공간 고정된 크기만큼 만들어 hash코드를 나누어서 배열에 나눠담는다. 즉, 해쉬코드 자체가 배열 인덱스로 작용하므로 direct로 배열에 접근하기에 빠름  
단점 : 이때, 해쉬코드를 배열에 나누어 담을때, 충돌(collison)현상을 막기위해 규칙을 잘 해야한다. 이를 Hash Algorithm이라고 한다. 너무 한군데에 몰려있으면 한 곳만 비교해도 모두 비교하는 거와 마찬가지가 되고, O(N)의 시간이 걸린다. 즉, 얼마나 잘 골고루 분배했느냐가 중요하다.

+2. ArrayList

Java의 경우 Array로 객체를 생성하면, 배열의 크기가 fixed된다. 그러나 ArrayList의 경우 크기가 유동적이다. 하지만 검색 시간은 O(1)의 시간이 걸린다.  
왜나하면, ArrayList에 배열이 다 차면, 배열을 두배로 늘리는 작업(Doubling)을 한다. 그렇기에 검색할때는 어차피 고정된 크기에서 검색을 한다.  
Doubling하는데 걸리는 시간은 원래 배열의 크기 n이면 o(n)의 시간이 소요된다. 그러나, 이러한 번거로운 과정에도 불구하고, 입력시간은 O(1)의 시간이 걸린다.  
왜냐하면, 더블링할때, 그전의 더블링은 n/2 시간 그전은 n/4시간이 걸림 모두더하면, n 이상의 시간이 걸리지않으므로 한번 검색하는 1이상의 시간은 걸리지 않음?

+3 StringBuilder



+) Big-O 표기법  
- 알고리즘의 성능을 수학적으로 표현한 표기법  
- 시간복잡도와 공간복잡도를 알 수 있음
- 알고리즘 실제 러닝 타임을 표시하는게 아니라, 데이터와 사용자의 증가율에 따른 알고리즘의 성능 예측하는 것이 목표  
(1) O(1) constant time(일정한 시간)  
: 입력 데이터 크기와 상관없이 언제나 일정한 시간이 걸리는 알고리즘을 말함
(2) O(n)  
: 입력 데이터 크기에 비례해서 처리시간이 걸리는 알고리즘을 말함  ex, for구문
(3) O(n^2) quadratic time  
: 입력 데이터 크기에 제곱비례해서 처리시간이 걸리는 알고리즘을 말함  ex, 이중 for구문  
(4) O(nm) 
: 입력 데이터 크기에 비례해서 처리시간이 걸리는 알고리즘을 말함  ex, 길이가 다른? 이중 for구문  
m변수 값에 따라  O(n^2)와 확연하게 차이가 있기때문에 구분해주어야함
(5) O(n^3) polynomial / cubic time  
: 입력 데이터 크기에 세제곱비례해서 처리시간이 걸리는 알고리즘을 말함 ex, 삼중 for구문  
(6) O(2^n) exponential time 
: Fibonacci(피보나치) 수열(재귀함수를 통해 구현)만큼 증가? 세제곱보다 더 급격하게 증가함  
그 밖에 m개씩 n번 늘어나는 알고리즘은 O(m^n)으로 표현  
(7) O(log n)  
: 한번 처리가 될때마다 검색해야할 데이터가 반으로 줄어드는 알고리즘 ex, binary search(이진 검색)  
O(n)보다 적게 걸린다. 또한 데이터가 증가해도 성능이 차이가 나지 않음  
(8) O(sqrt(n))  
: Square root ? 제곱근  
정사각형 이차원 배열에서 하나의 행만 검색하는 것과 마찬가지  
- Drop constants : 빅오 표기법에서 상수를 과감하게 버림 즉, O(2n) => for구문을 따로 두개 돌리는 알고리즘 이면,  
상수 2는 과감하게 버리고 O(n)이 된다. 왜냐하면 러닝타입을 표시하는게 아니라 증가율에 다른 성능 예측을 하는것이 목표이기 때문에 상수는 과감하게 무시함